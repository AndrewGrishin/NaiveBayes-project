{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from NaiveBayesModel import NaiveBayesClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(selectors: dict):\n",
    "    def get_encoded_val(val, selectors=selectors):\n",
    "        assert val in selectors.keys(), '{} not in keys!'.format(val)\n",
    "        return selectors[val]\n",
    "\n",
    "    def transformation(data):\n",
    "        new_data = list(map(get_encoded_val, data))\n",
    "        return np.array(new_data)\n",
    "\n",
    "    return transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'virginica', 'setosa', 'versicolor'}\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "encoding = data['target_names']\n",
    "\n",
    "DECODING = {key: val for key, val in enumerate(encoding)}\n",
    "ENCODING = {val: key for key, val in DECODING.items()}\n",
    "encode_transform = transform(ENCODING) \n",
    "decode_transform = transform(DECODING)\n",
    "\n",
    "y = decode_transform(y)\n",
    "print(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "new_X = np.divide(X, X.mean(axis=0))\n",
    "pca = PCA(n_components=2)\n",
    "new_X = pca.fit_transform(new_X)\n",
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X\n",
    "new_data = np.concatenate([new_X, y.reshape(-1, 1)], axis=1)\n",
    "columns = ['sep_len', 'sep_wid', 'pet_len', 'pet_wid', 'class']\n",
    "pd_new_data = pd.DataFrame(new_data, columns=columns)\n",
    "\n",
    "setosa = new_data[new_data[:, -1] == 'setosa']\n",
    "setosa = pd.DataFrame(setosa, columns=columns)\n",
    "\n",
    "versicolor = new_data[new_data[:, -1] == 'versicolor']\n",
    "versicolor = pd.DataFrame(versicolor, columns=columns)\n",
    "\n",
    "virginica = new_data[new_data[:, -1] == 'virginica']\n",
    "virginica = pd.DataFrame(virginica, columns=columns)\n",
    "\n",
    "# pd_new_data.to_csv('iris_pca_2.csv', sep= ' ', index=False)\n",
    "# setosa.to_csv('setosa_pca_2.csv', sep= ' ', index=False)\n",
    "# versicolor.to_csv('versicolor_pca_2.csv', sep= ' ', index=False)\n",
    "# virginica.to_csv('virginica_pca_2.csv', sep= ' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(series: pd.Series) -> pd.Series:\n",
    "    convert = lambda x: float(x)\n",
    "    new_series = series.apply(convert)\n",
    "    return new_series\n",
    "\n",
    "def df_to_float(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = to_float(df[column])\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = df_to_float(setosa)\n",
    "virginica = df_to_float(virginica)\n",
    "versicolor = df_to_float(versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-val: setosa:\n",
      "0.45951762795448303 0.27151283621788025 0.054810501635074615 8.658647061565716e-07\n",
      "P-val: versicolor:\n",
      "0.46474334597587585 0.3379890024662018 0.15847881138324738 0.027278577908873558\n",
      "P-val: virginica:\n",
      "0.2583250105381012 0.1808987259864807 0.10977514833211899 0.08695416152477264\n"
     ]
    }
   ],
   "source": [
    "print('P-val: setosa:')\n",
    "print(shapiro(X[y == 'setosa', 0]).pvalue, shapiro(X[y == 'setosa', 1]).pvalue, shapiro(X[y == 'setosa', 2]).pvalue, shapiro(X[y == 'setosa', 3]).pvalue)\n",
    "print('P-val: versicolor:')\n",
    "print(shapiro(X[y == 'versicolor', 0]).pvalue, shapiro(X[y == 'versicolor', 1]).pvalue, shapiro(X[y == 'versicolor', 2]).pvalue, shapiro(X[y == 'versicolor', 3]).pvalue)\n",
    "print('P-val: virginica:')\n",
    "print(shapiro(X[y == 'virginica', 0]).pvalue, shapiro(X[y == 'virginica', 1]).pvalue, shapiro(X[y == 'virginica', 2]).pvalue, shapiro(X[y == 'virginica', 3]).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.arange(1e-1, 0.95, 0.025)\n",
    "metrics = dict(size=[], acc=[], f1=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2279b89624b547d1a7f152d756cd3cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train size:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(train_sizes, desc='Train size')\n",
    "for train_size in pbar:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, shuffle=True, random_state=SEED, stratify=y)\n",
    "    nb = NaiveBayesClassifier()\n",
    "    encoding = nb.fit(X_train, y_train) \n",
    "    y_preds = nb.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds, average='macro')\n",
    "\n",
    "    metrics['size'].append(train_size)\n",
    "    metrics['acc'].append(acc)\n",
    "    metrics['f1'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "# metrics.to_csv('metrics_train.csv', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.962116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.945729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.935734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.950610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.938586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.945195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.934220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.950970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.947090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.945355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.953968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>0.952320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.949668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.934921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.929630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.925697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.919118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.913889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.922963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.962848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.896825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.877778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.915344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     size       acc        f1\n",
       "0   0.100  0.955556  0.955556\n",
       "1   0.125  0.962121  0.962116\n",
       "2   0.150  0.945312  0.945729\n",
       "3   0.175  0.935484  0.935734\n",
       "4   0.200  0.950413  0.950610\n",
       "5   0.225  0.965812  0.965812\n",
       "6   0.250  0.938053  0.938586\n",
       "7   0.275  0.944954  0.945195\n",
       "8   0.300  0.933962  0.934220\n",
       "9   0.325  0.950980  0.950970\n",
       "10  0.350  0.938776  0.939394\n",
       "11  0.375  0.946809  0.947090\n",
       "12  0.400  0.945055  0.945355\n",
       "13  0.425  0.954023  0.953968\n",
       "14  0.450  0.951807  0.952320\n",
       "15  0.475  0.949367  0.949668\n",
       "16  0.500  0.947368  0.947692\n",
       "17  0.525  0.944444  0.944348\n",
       "18  0.550  0.941176  0.941919\n",
       "19  0.575  0.937500  0.937951\n",
       "20  0.600  0.934426  0.934921\n",
       "21  0.625  0.929825  0.929630\n",
       "22  0.650  0.924528  0.925697\n",
       "23  0.675  0.918367  0.919118\n",
       "24  0.700  0.913043  0.913889\n",
       "25  0.725  0.928571  0.928480\n",
       "26  0.750  0.921053  0.922963\n",
       "27  0.775  0.911765  0.913043\n",
       "28  0.800  0.903226  0.904762\n",
       "29  0.825  0.962963  0.962848\n",
       "30  0.850  0.913043  0.916667\n",
       "31  0.875  0.894737  0.896825\n",
       "32  0.900  0.875000  0.877778\n",
       "33  0.925  0.916667  0.915344"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_1 = 0.225\n",
    "train_size_2 = 0.825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(X_train: np.array, y_train: np.array) -> NaiveBayesClassifier:\n",
    "    clf = NaiveBayesClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def get_score(clf: NaiveBayesClassifier, score: sklearn.metrics, X_test: np.array, y_test: np.array, params: dict = dict()) -> float:\n",
    "    y_preds = clf.predict(X_test)\n",
    "    metrics = score(y_test, y_preds, **params)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9658119658119658, 0.9658119658119658)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(average='macro')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=train_size_1, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=SEED, \n",
    "                                                    stratify=y)\n",
    "model_1 = get_model(X_train, y_train)\n",
    "\n",
    "acc_1 = get_score(model_1, accuracy_score, X_test, y_test)\n",
    "f1_1 = get_score(model_1, f1_score, X_test, y_test, params)\n",
    "\n",
    "acc_1, f1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.95454545, 3.36363636, 1.46363636, 0.21818182],\n",
       "        [5.92727273, 2.7       , 4.24545455, 1.3       ],\n",
       "        [6.70909091, 2.94545455, 5.78181818, 1.99090909]]),\n",
       " array([[0.07472727, 0.14654545, 0.02054545, 0.00963636],\n",
       "        [0.37218182, 0.146     , 0.23272727, 0.032     ],\n",
       "        [0.53490909, 0.16272727, 0.46163636, 0.08290909]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.mu, model_1.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9629629629629629, 0.9628482972136223)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=train_size_2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=SEED,\n",
    "                                                    stratify=y)\n",
    "model_2 = get_model(X_train, y_train)\n",
    "\n",
    "acc_2 = get_score(model_2, accuracy_score, X_test, y_test)\n",
    "f1_2 = get_score(model_2, f1_score, X_test, y_test, params)\n",
    "\n",
    "acc_2, f1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.mu, model_1.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "x2_min, x2_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "h = 1e-3\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                     np.arange(x2_min, x2_max, h))\n",
    "\n",
    "xx.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(average='macro')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, [0, 2]], y, \n",
    "                                                    train_size=train_size_1, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=SEED, \n",
    "                                                    stratify=y)\n",
    "model_1 = get_model(X_train, y_train)\n",
    "\n",
    "acc_1 = get_score(model_1, accuracy_score, X_test, y_test)\n",
    "f1_1 = get_score(model_1, f1_score, X_test, y_test, params)\n",
    "\n",
    "acc_1, f1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(18, 5))\n",
    "Z = model_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "axis.contourf(xx, yy, Z)\n",
    "axis.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=train_size_2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=SEED,\n",
    "                                                    stratify=y)\n",
    "model_2 = get_model(X_train, y_train)\n",
    "\n",
    "acc_2 = get_score(model_2, accuracy_score, X_test, y_test)\n",
    "f1_2 = get_score(model_2, f1_score, X_test, y_test, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stdDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
